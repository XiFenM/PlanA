We are seeking a skilled developer to build production-grade AI applications, focusing on LLM-based agents and tool-using systems. You will integrate large language models (LLMs), retrieval-augmented generation (RAG), and external tools/APIs on GPU-accelerated stacks, enhancing agent frameworks for reliability, scalability, and safety.  
我们正在寻找一位技术娴熟的开发者，用于构建生产级 AI 应用，重点在于基于 LLM 的代理和工具使用系统。您将集成大型语言模型（LLMs）、检索增强生成（RAG）以及外部工具/API，在 GPU 加速的堆栈上，增强代理框架的可靠性、可扩展性和安全性。

**What You’ll Be Doing:  您将负责的工作：**

- Design, implement, and deploy AI-powered features using LLMs, including autonomous and multi-agent workflows.  
    使用 LLM 设计、实现和部署 AI 功能，包括自主和多代理工作流程。
    
- Build agent toolchains, including planning, tool/function calling, memory management, RAG integration, and enterprise API connectivity.  
    构建代理工具链，包括规划、工具/函数调用、内存管理、RAG 集成和企业 API 连接。
    
- Enhance agent frameworks with custom planners, routers, concurrency control, state management, and retry mechanisms.  
    为代理框架添加自定义规划器、路由器、并发控制、状态管理和重试机制。
    
- Develop evaluation and observability systems to monitor agent performance (success rates, tool-call accuracy, latency, cost, traces).  
    开发评估和可观察性系统，以监控代理性能（成功率、工具调用准确率、延迟、成本、跟踪记录）。
    
- Implement safety and compliance measures, including content filtering, PII handling, and policy enforcement using guardrail frameworks.  
    实施安全和合规措施，包括内容过滤、个人身份信息处理和政策执行，使用护栏框架。
    
- Optimize inference pipelines for GPU performance, latency, and cost; deploy via microservices and APIs.  
    优化推理管道的 GPU 性能、延迟和成本；通过微服务和 API 进行部署。
    
- Manage CI/CD, containerization, and deployment; maintain monitoring, logging, and alerting; and produce clear documentation.  
    管理 CI/CD、容器化和部署；维护监控、日志和警报；并产出清晰的文档。
    

**What we need to see:  
我们需要看到：**

- BS or MS in Computer Science, Electrical/Computer Engineering, or a related field.  
    计算机科学、电气/计算机工程或相关领域的学士或硕士学位。
    
- 2–3 years of experience building AI applications, with at least 1 year focused on developing LLM-based agents (e.g., tool use, function calling, ReAct-style reasoning, RAG integration).  
    2-3 年构建 AI 应用的经验，至少 1 年专注于开发基于 LLM 的代理（例如，工具使用、函数调用、ReAct 式推理、RAG 集成）。
    
- Strong programming skills in Python and one of C++, JavaScript, or TypeScript.  
    精通 Python 编程，并掌握 C++、JavaScript 或 TypeScript 中的一种。
    
- Experience with an agent framework such as LangChain Agents/LangGraph, AutoGen, CrewAI, Semantic Kernel, or Haystack Agents.  
    熟悉代理框架，如 LangChain Agents/LangGraph、AutoGen、CrewAI、Semantic Kernel 或 Haystack Agents。
    
- Proficiency in creating custom tools/functions, integrating external APIs, and working with async workflows and retries.  
    精通创建自定义工具/函数、集成外部 API 以及处理异步工作流和重试。
    
- Practical experience with privacy, responsible AI practices, prompt engineering, and content filtering.  
    具备隐私、负责任 AI 实践、提示工程和内容过滤的实际经验。
    
- Familiarity with PyTorch or TensorFlow, REST/gRPC, Docker, cloud platforms (AWS, Azure, or GCP), and databases (SQL/NoSQL, vector DBs).  
    熟悉 PyTorch 或 TensorFlow、REST/gRPC、Docker、云平台（AWS、Azure 或 GCP）和数据库（SQL/NoSQL、向量数据库）。
    

**Ways to stand out from the crowd:  
脱颖而出的方法：**

- Experience customizing agent frameworks (e.g., planners, routers, memory, tool management, conversation state machines).  
    在定制代理框架方面的经验（例如，规划器、路由器、内存、工具管理、对话状态机）。
    
- Expertise in multi-agent systems, workflow orchestration, or event-driven designs; familiarity with structured output (e.g., JSON schema, OpenAPI).  
    在多代理系统、工作流编排或事件驱动设计方面的专业知识；熟悉结构化输出（例如，JSON 模式、OpenAPI）。
    
- Knowledge of evaluation and guardrail systems (e.g., NeMo Guardrails, Guardrails AI, custom evaluation harnesses, A/B testing, telemetry).  
    对评估和护栏系统的了解（例如，NeMo 护栏、Guardrails AI、自定义评估框架、A/B 测试、遥测）。
    
- Experience optimizing GPU inference with tools like NVIDIA Triton Inference Server, TensorRT, or RAG tooling.  
    使用 NVIDIA Triton 推理服务器、TensorRT 或 RAG 工具等工具优化 GPU 推理的经验。
    
- Skills in retrieval efficiency (e.g., ANN, indexing), caching, or cost-aware inference.  
    在检索效率（例如，ANN、索引）、缓存或成本感知推理方面的技能。