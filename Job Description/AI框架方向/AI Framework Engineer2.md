## Job Description   职位描述

  

**WHAT YOU DO AT AMD CHANGES EVERYTHING**   
你在 AMD 所做的一切都将改变一切

At AMD, our mission is to build great products that accelerate next-generation computing experiences—from AI and data centers, to PCs, gaming and embedded systems. Grounded in a culture of innovation and collaboration, we believe real progress comes from bold ideas, human ingenuity and a shared passion to create something extraordinary. When you join AMD, you’ll discover the real differentiator is our culture. We push the limits of innovation to solve the world’s most important challenges—striving for execution excellence, while being direct, humble, collaborative, and inclusive of diverse perspectives. Join us as we shape the future of AI and beyond.  **Together, we advance your career.**    
在 AMD，我们的使命是打造卓越的产品，加速下一代计算体验——从人工智能和数据中心，到个人电脑、游戏和嵌入式系统。我们植根于创新和协作的文化，相信真正的进步源于大胆的构想、人类的智慧以及共同创造非凡事物的热情。当你加入 AMD 时，你会发现真正的差异化在于我们的文化。我们不断突破创新极限，以解决世界上最重要的挑战——追求执行卓越，同时保持直接、谦逊、协作和包容不同观点。加入我们，共同塑造人工智能的未来。一起，我们助你事业腾飞。

  

**Position Overview  职位概述**  
We are seeking a highly experienced engineer specializing in large language model (LLM) inference performance optimization. You will be a core member of our team, responsible for building and optimizing the LLM inference performance with high-throughput, low-latency on AMD Instinct GPUs. If you are passionate about pushing performance boundaries and have deep, hands-on expertise with cutting-edge technologies like vLLM or SGLang, we invite you to join us.  
我们正在寻找一位在大型语言模型（LLM）推理性能优化方面经验丰富的工程师。您将成为我们团队的核心成员，负责在 AMD Instinct GPU 上构建和优化具有高吞吐量、低延迟的 LLM 推理性能。如果您热衷于突破性能极限，并且对 vLLM 或 SGLang 等尖端技术拥有深厚的实践经验，我们诚邀您加入我们。  
**Key Responsibilities  主要职责**  
1. Core System Optimization: Lead the development, tuning, and customization of LLM performance optimization on AMD GPUs, leveraging and extending frameworks like vLLM or SGLang to address performance bottlenecks in production environments.  
2. 核心系统优化：领导在 AMD GPU 上开发、调优和定制 LLM 性能优化，利用并扩展 vLLM 或 SGLang 等框架来解决生产环境中的性能瓶颈。  
3. Performance Analysis & Tuning: Conduct end-to-end performance profiling using specialized tools. Perform deep optimization of compute-bound operators (e.g., Attention), memory I/O, and communication to significantly increase throughput and reduce latency.  
4. 性能分析与调优：使用专业工具进行端到端性能分析。对计算密集型算子（例如 Attention）进行深度优化，优化内存 I/O 和通信，显著提高吞吐量并降低延迟。  
5. Model Architecture Adaptation: Demonstrate expertise in mainstream LLM architectures (e.g., DeepSeek, Qwen, Llama, ChatGLM) and optimize inference for their specific characteristics (e.g., RoPE, SWA, MoE, GQA).  
6. 模型架构适配：展示在主流 LLM 架构（例如 DeepSeek、Qwen、Llama、ChatGLM）方面的专业知识，并针对其特定特性（例如 RoPE、SWA、MoE、GQA）优化推理。  
7. Algorithm & Principle Application: Leverage your deep understanding of core algorithms (Transformer, Attention, MoE) to implement advanced optimization techniques such as PagedAttention, FlashAttention, continuous batching, quantization, and model compression.  
8. 算法与原理应用：利用对核心算法（Transformer、Attention、MoE）的深入理解，实现高级优化技术，如 PagedAttention、FlashAttention、连续批处理、量化和模型压缩。  
9. Technology Foresight & Implementation: Research and prototype state-of-the-art optimization techniques (e.g., Speculative Decoding, Weight-Only Quantization) and drive their adoption into production systems.  
10. 技术前瞻与实施：研究和原型化最先进的优化技术（例如推测解码、仅权重量化），并推动其在生产系统中的采用。

  
Qualifications:  资质：  
**Mandatory Requirements:  必备要求：**  
1. Expertise in Inference Frameworks: Proven, hands-on experience with vLLM or SGLang, including deep understanding of their source code, deployment, configuration, and performance tuning. (Please describe relevant projects in your resume).  
2. 推理框架专长：具备 vLLM 或 SGLang 的实际操作经验，包括对其源代码、部署、配置和性能调优的深入理解。（请在简历中描述相关项目）  
3. Mastery of Model Architectures: In-depth understanding and practical experience with inference workflows of mainstream LLMs (e.g., DeepSeek, Qwen), including their tokenizers, model configurations, and architecture definitions.  
4. 模型架构掌握：深入理解并具备主流 LLMs（例如，DeepSeek、Qwen）推理工作流的实践经验，包括其分词器、模型配置和架构定义。  
5. Strong Theoretical Foundation: Solid grasp of the principles behind Transformer, Self-Attention, MoE, KV Cache, and their impact on inference performance.  
6. 扎实的理论基础：对 Transformer、自注意力机制、MoE、KV 缓存等原理有牢固掌握，并了解其对推理性能的影响。  
7. Proven Optimization Experience: Familiarity with end-to-end LLM inference optimization techniques such as PagedAttention, FlashAttention, continuous/dynamic batching, and quantization (INT8/INT4/GPTQ/AWQ), demonstrated with successful case studies.  
8. 丰富的优化经验：熟悉端到端 LLM 推理优化技术，如 PagedAttention、FlashAttention、连续/动态批处理和量化（INT8/INT4/GPTQ/AWQ），并有成功的案例研究证明。  
9. Programming Skills: Proficiency in Python and strong software engineering best practices.  
10. 编程技能：精通 Python，并具备强大的软件工程最佳实践能力。  
**Preferred Qualifications (Plus):  
优先资质（加分项）：**  
11. Low-Level Development Skills: Experience with CUDA C++ programming for writing and debugging high-performance GPU kernels; or practical experience using Triton to develop and optimize deep learning operators.  
12. 低级开发技能：具有使用 CUDA C++编写和调试高性能 GPU 内核的经验；或使用 Triton 开发和优化深度学习算子的实际经验。  
13. Compiler Knowledge: Understanding or practical experience with compiler technologies like TVM or MLIR is a significant advantage.  
14. 编译器知识：了解或具有 TVM 或 MLIR 等编译技术的经验是一个显著优势。  
15. Distributed Systems Experience: Hands-on experience with distributed inference for large-scale models (e.g., Tensor Parallel, Pipeline Parallel).  
16. 分布式系统经验：具有大规模模型分布式推理的实际经验（例如，张量并行、流水线并行）。  
17. Education: Master's or Ph.D. in Computer Science, Artificial Intelligence, Electrical Engineering, or a related field.  
18. 教育背景：计算机科学、人工智能、电气工程或相关领域的硕士或博士学位。

#LI-FL1

  

_Benefits offered are described:_  [AMD benefits at a glance](https://amd.jibeapply.com/benefits).  
提供的福利如下：AMD 福利概览。

_AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law.   We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.  
AMD 不接受猎头公司、招聘机构或付费招聘服务的未经请求的简历。AMD 及其子公司是平等机会、包容性的雇主，并将不考虑年龄、血统、肤色、婚姻状况、健康状况、精神或身体残疾、国籍、种族、宗教、政治和/或第三方关系、性别、怀孕、性取向、性别认同、军人或退伍军人身份，或任何其他受法律保护的特征来考虑所有申请人。我们鼓励所有符合条件的候选人申请，并在招聘和选拔过程的各个阶段根据相应法律满足申请人的需求。_