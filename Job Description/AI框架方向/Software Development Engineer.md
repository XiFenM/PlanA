## Job Description

  

WHAT YOU DO AT AMD CHANGES EVERYTHING

At AMD, our mission is to build great products that accelerate next-generation computing experiences—from AI and data centers, to PCs, gaming and embedded systems. Grounded in a culture of innovation and collaboration, we believe real progress comes from bold ideas, human ingenuity and a shared passion to create something extraordinary. When you join AMD, you’ll discover the real differentiator is our culture. We push the limits of innovation to solve the world’s most important challenges—striving for execution excellence, while being direct, humble, collaborative, and inclusive of diverse perspectives. Join us as we shape the future of AI and beyond. Together, we advance your career.

  

THE ROLE: 

As a core member of the team, you will play a pivotal role in optimizing and developing deep learning frameworks for AMD GPUs. Your strong experience will be critical in enhancing GPU kernels, deep learning models, and training/inference performance across multi-GPU and multi-node systems. You will engage with both internal GPU library teams and open-source maintainers to ensure seamless integration of optimizations, utilizing cutting-edge compiler technologies and advanced engineering principles to drive continuous improvement.

THE PERSON:   

Highly skilled engineer with strong technical and analytical expertise in C++ development within Linux environments. The ideal candidate will thrive in both collaborative team settings and independent work, with the ability to define goals, manage development efforts, and deliver high-quality solutions. Strong problem-solving skills, a proactive approach, and a keen understanding of software engineering best practices are essential.

KEY RESPONSIBILITIES: 

- Optimize Deep Learning Frameworks: Enhance and optimize frameworks like TensorFlow and PyTorch for AMD GPUs in open-source repositories.
    
- Develop GPU Kernels: Create and optimize GPU kernels to maximize performance for specific AI operations.
    
- Develop & Optimize Models: Design and optimize deep learning models specifically for AMD GPU performance.
    
- Collaborate with GPU Library Teams: Work closely with internal teams to analyze and improve training and inference performance on AMD GPUs.
    
- Collaborate with Open-Source Maintainers: Engage with framework maintainers to ensure code changes are aligned with requirements and integrated upstream.
    
- Work in Distributed Computing Environments: Optimize deep learning performance on both scale-up (multi-GPU) and scale-out (multi-node) systems.
    
- Utilize Cutting-Edge Compiler Tech: Leverage advanced compiler technologies to improve deep learning performance.
    
- Optimize Deep Learning Pipeline: Enhance the full pipeline, including integrating graph compilers.
    
- Software Engineering Best Practices: Apply sound engineering principles to ensure robust, maintainable solutions.
    
- Mentor and Guide: Provide mentorship to junior team members, fostering growth and collaboration through code reviews, knowledge sharing, and technical guidance.
    

PREFERRED EXPERIENCE: 

- GPU Kernel Development & Optimization: Strong experience in designing and optimizing GPU kernels for deep learning on AMD GPUs using HIP, CUDA, and assembly (ASM). Strong knowledge of AMD architectures (GCN, RDNA) and low-level programming to maximize performance for AI operations, leveraging tools like Compute Kernel (CK), CUTLASS, and Triton for multi-GPU and multi-platform performance.
    
- Deep Learning Integration: Strong experience in integrating optimized GPU performance into machine learning frameworks (e.g., TensorFlow, PyTorch) to accelerate model training and inference, with a focus on scaling and throughput.
    
- Software Engineering: Expert skills in Python and C++, with experience in debugging, performance tuning, and test design to ensure high-quality, maintainable software solutions.
    
- High-Performance Computing: Strong experience in running large-scale workloads on heterogeneous compute clusters, optimizing for efficiency and scalability.
    
- Compiler Optimization: Sound understanding of compiler theory and tools like LLVM and ROCm for kernel and system performance optimization.
    

ACADEMIC CREDENTIALS: 

- Master’s degree in Computer Science, Computer Engineering, Electrical Engineering, or a related field.
    
- 5+ years of professional experience in technical software development, with a focus on GPU optimization, performance engineering, and framework development.
    

#LI-FL1

  

_Benefits offered are described:_ [AMD benefits at a glance](https://amd.jibeapply.com/benefits).

_AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process._