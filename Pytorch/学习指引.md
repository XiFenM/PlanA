模块一：PyTorch 内部机制 (Framework Internals)

**核心目标**：从“API 调用者”转变为“框架开发者”。理解数据在 Python 到 C++ 再到硬件指令流转的全过程，特别是针对非 CUDA 硬件的适配（PrivateUse1、Dispatcher、Autograd）。

**预计耗时**：4 - 6 周（每周投入约 8-10 小时）

#### 1. 学习路线图与核心知识点

这一部分我们将按照数据流动的方向，自顶向下深入核心组件：

- **第 1 周：张量与存储的二元性 (Tensor Physics)**
    
    - **目标**：理解 `Tensor` (View) 与 `Storage` (Data) 的分离，掌握步长（Stride）对性能的影响。
        
    - **关键点**：
        
        - `c10::TensorImpl` 结构分析。
            
        - Stride 机制：为什么 `view()` 是零拷贝？为什么需要 `.contiguous()`？
            
        - 内存布局：Row-major vs. Column-major，以及在自定义硬件上的 padding/alignment 要求。
            
    - **思考题**：如果你的自研芯片要求数据必须是 32 字节对齐，你如何在 Allocator 层面处理？
        
- **第 2 周：算子派发机制 (The Dispatcher)**
    
    - **目标**：理解 `torch.add` 是如何找到你写的 C++ Kernel 的。这是自研芯片接入 PyTorch 的核心入口。
        
    - **关键点**：
        
        - **Dispatch Key Set**：理解 `CPU`, `CUDA`, `Autograd`, `PrivateUse1` 等 Key 的优先级。
            
        - **算子注册**：`TORCH_LIBRARY`, `TORCH_LIBRARY_IMPL` 宏背后的机制。
            
        - **Boxed vs. Unboxed**：性能与通用性的权衡。
            
        - **Backend Select**：如何让 PyTorch 自动选择你的硬件后端。
            
- **第 3 周：自动微分引擎 (Autograd Engine)**
    
    - **目标**：掌握动态图构建与梯度传播原理，特别是自定义 Function 的实现。
        
    - **关键点**：
        
        - **DAG 构建**：`Node` (grad_fn), `Edge`, `AccumulateGrad` 的生命周期。
            
        - **反向传播流程**：拓扑序执行，`.backward()` 的 C++ 实现逻辑。
            
        - **Checkpointing**：`torch.utils.checkpoint` 的底层实现（用时间换空间）。
            
    - **实战**：阅读 `torch/csrc/autograd` 下的核心代码。
        
- **第 4 周：内存管理与扩展 (Memory & Extensions)**
    
    - **目标**：理解显存复用机制，并尝试为新硬件编写插件。
        
    - **关键点**：
        
        - **Caching Allocator**：PyTorch 如何管理显存池（Pool），避免碎片化（Fragmentation）。
            
        - **PrivateUse1 实战**：利用 PyTorch 的扩展机制注册一个虚拟的设备。
            
        - **Structured Kernels (Meta Tensors)**：理解 PyTorch 2.0 中 Meta Kernel 的作用（仅推导 Shape 不计算），这是支持 `torch.compile` 的前提。
            

---

#### 2. 精选学习资料推荐

为了避免在浩如烟海的源码中迷失，我为你精选了以下资料，请按照优先级阅读：

**A. 必读核心材料 (High Priority)**

1. **Edward Z. Yang 的博客 (PyTorch 核心开发者)**
    
    - _ezyang's blog on PyTorch Internals_: 这是公认的圣经。
        
    - 重点阅读：[Let’s talk about the PyTorch dispatcher](http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/) 和 [PyTorch internal architecture tour](http://blog.ezyang.com/2019/05/pytorch-internals/)。
        
    - _理由_：他详细解释了 Dispatcher 的设计哲学，这是你作为非 CUDA 开发者必须掌握的路由机制。
        
2. **PyTorch 官方源码 (GitHub)**
    
    - 不要只看 Python 代码！你需要 Clone 仓库并打开 `aten/src/ATen/native` 目录。
        
    - _推荐路径_：
        
        - `c10/core/DispatchKey.h` (查看 Key 的定义)
            
        - `aten/src/ATen/native/BinaryOps.cpp` (查看 `add` 算子是如何定义的)
            
        - `torch/csrc/autograd/engine.cpp` (硬核：Autograd 引擎的主循环)
            
3. **Quansight 的 PyTorch Internals 指南**
    
    - 网上有一些 Quansight 工程师分享的 Slide 或文章，通常对 Structured Kernels 解释得很清楚。
        

**B. 辅助理解材料 (Medium Priority)**

1. **《指引.md》 (你上传的文件)**
    
    - 重读第 2 章节：**“张量（Tensor）的物理与逻辑二元性”** 和 **“调度器（Dispatcher）：算子路由的艺术”**。这部分总结得非常精炼，适合复习。
        
2. **《初级成长计划.md》 (你上传的文件)**
    
    - 重读第 2 章节：**“技术深潜：PyTorch 框架内核与运行时机制”**，特别是关于 PrivateUse1 和 Meta Tensors 的部分。
        

---

#### 3. 动手实践任务 (Actionable Tasks)

光学不练是无法理解系统底层的。建议你在公司的开发机或个人电脑上完成以下任务：

- **任务一：手动追踪 Dispatcher**
    
    - **操作**：在 PyTorch 源码中（比如 `aten/src/ATen/native/BinaryOps.cpp` 的 `add` 函数入口处）添加 `printf` 或 `std::cout` 日志，重新编译 PyTorch。
        
    - **验证**：在 Python 端运行 `torch.add(a, b)`，观察日志输出，确认调用路径。
        
    - **进阶**：尝试注册一个新的 `PrivateUse1` 设备，并让 `torch.add` 能够调度到你写的空函数上。
        
- **任务二：可视化 Autograd Graph**
    
    - **操作**：使用 `torchviz` 库可视化一个简单的神经网络（如 MLP）的计算图。
        
    - **深入**：不仅仅看图，尝试打印 `tensor.grad_fn`，并沿着 `grad_fn.next_functions` 手动遍历链表，模拟一遍反向传播的路径寻找过程。
        
- **任务三：编写一个自定义 Allocator (模拟)**
    
    - **操作**：阅读 `c10::cuda::CUDACachingAllocator` 的代码逻辑。
        
    - **思考**：如果你的自研芯片不支持 `realloc`，或者有特殊的 Bank Conflict 限制，你会如何修改这个 Allocator？尝试写伪代码描述你的分配策略（比如 Best-fit vs First-fit）。
        

---

**你现在的感受如何？** 关于 PyTorch 内部机制，你之前在工作中是否遇到过具体的痛点（比如算子注册报错、显存泄漏查不到原因），我们可以结合那个具体案例来深入探讨。