本章节的学习材料主要以Jax的《How to Scale Your Model: A Systems View of LLMs on TPUs》为核心，以翻译为主，中间也会夹杂一些译者的理解和笔记（会区分标出）。本书主要介绍TPU在大规模模型上的特性，也会与GPU进行对比。
链接： https://jax-ml.github.io/scaling-book/

让我们开始吧。
# 引言

训练一个大语言模型往往感觉像是炼丹术 (alchemy），但理解并优化一个模型并非如此。本系列旨在揭示 (demystify) 扩展语言模型的科学。
1. TPUs（和 GPUs）是如何工作的？他们之间是如何通信的？
2. LLMs是如何运行在真实硬件上的？
3. 如何在训练和推理中将模型并行化，从而使得他们能在大规模下高效运行？
4. 这个大语言模型的训练成本是多少？
5. 我需要多少内存来部署这个模型？
6. 什么是All Gather？
如果你对以上问题感兴趣，那么我相信接下来的内容将会对你有所帮助。

虽然深度学习的大部分内容依旧归结于（boil down to）某种黑魔法，但优化你的模型性能并非如此——即使是大规模模型！在模型性能优化中其实存在着相对简单的底层逻辑——从单个加速芯片到万卡加速集群——理解这些底层逻辑能让你做到许多有用的事：
- 估算（Ballpack）你的模型各个部分与理论最优值的接近程度。
- 在不同规模下就最佳的并行策略做出明智选择（make informed choices）（如何将计算分配到不同的设备上）
- 估算训练和运行大型Transformer模型的成本和时间。
- 设计能充分利用特定硬件特性的算法。
	- [Flash Attention](https://arxiv.org/abs/2205.14135) 
	- [Fast Transformer Decoding](https://arxiv.org/abs/1911.02150) 
	- [Data Movement Is All You Need](https://arxiv.org/abs/2007.00072) 
- 由对于当前算法性能瓶颈的清晰理解驱动，从而设计硬件。

**预期前提背景**
我们将假设你对LLMs和Transformer架构有基本的理解，但不一定了解他们在规模化运作中的原理。希望你了解一些关于LLM训练的背景知识， 最好对Jax也有基本的熟悉度。
一些有用的背景阅读材料：
1. 关于Transformer架构的博客：[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) 
2. 最初的Transformer论文：[Attention Is All You Need](https://arxiv.org/abs/1706.03762) 

**目标与反馈**
学习完本系列后，你应该能从从容容游刃有余地在任意给定硬件平台上设计估量Transformer模型的最佳并行策略方案，以及训练和推理大致需要多久时间。

如果你结果匆匆忙忙连滚带爬，请留下评论一起讨论你的困惑之处。我们可以一起改进我们的表达和学习方式。

## 为什么我们需要关心大规模模型性能优化？

在三到四年前，我认为大多数机器学习研究者不需要学习理解本系列的内容。但是如今，即便是“小”模型的运行也非常接近硬件极限。
历史上，机器学习的研究重点总是在“系统创新“与”软件改进“之间来回循环，如同时钟里的tik-tok循环。Alex Krizhevsky甚至编写了“邪恶的”（unholy）CUDA代码来加速CNN的运行。但几年之内，像Tensorflow这种库的出现意味着不再需要编写CUDA代码。也许这种情况也会在本系列所讨论的大规模模型性能优化的场景出现，本系列所讲述的内容也可能被抽象掉。
但scaling law已经并还将持续地将我们的模型推向硬件的最前沿。而且在可预见的未来，进行尖端研究将不可避免地

