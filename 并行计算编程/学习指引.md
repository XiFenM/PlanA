我们进入**第三部分：并行计算编程**。这一部分的核心不在于学会写 CUDA C++，而在于掌握**数据的流动（Data Movement）与计算的抽象（Compute Abstraction）**。

---

### ⚡ 模块三：并行计算编程 (Parallel Computing Programming)

**核心目标**：跳出单线程思维，掌握 GPU/NPU 的块级（Block-level）和片级（Tile-level）编程范式。重点在于利用 Triton 和 TileLang 等工具，以 Python 的抽象层级实现接近手写汇编的性能，并理解如何将其映射到自研芯片的指令集上。

**预计耗时**：8 - 10 周

#### 1. 学习路线图与核心知识点

我们将从最 Pythonic 的 Triton 入手，逐步深入到更底层的 Layout 抽象和显式调度。

第一层：Triton —— 块级编程范式 (The Block-Based Paradigm)

时间：第 1-4 周

Triton 是目前性价比最高的算子开发语言，它屏蔽了复杂的线程同步和共享内存管理。

- **1.1 编程模型转变**
    
    - **从 SIMT 到 Block-based**：CUDA 需要你控制每个线程（Thread 0 读地址 A），而 Triton 让你操作数据块（Block）。你需要习惯使用**块指针（Block Pointer）**来加载和存储整个数据块。
        
    - **编译器魔法**：理解 Triton 编译器如何自动处理**内存合并访问（Coalescing）和共享内存预取（Prefetching）**。这是它能逼近手写性能的关键。
        
- **1.2 核心算子实现**
    
    - **Element-wise 与 Reduction**：从简单的向量加法和 Softmax 入手。
        
    - **MatMul 与分块策略**：学习如何将大矩阵切分为 Tile，并在 SRAM（L1 Cache）中复用数据以减少 HBM 访问。
        
    - **FlashAttention**：Triton 的杀手级应用。理解如何在 SRAM 中保留中间结果（统计量），避免反复读写全局显存，从而突破访存墙（Memory Wall）。
        
- **1.3 后端与可移植性 (战略重点)**
    
    - 对于自研芯片，你需要关注 **Triton IR (TTIR)** 到 **LLVM IR** 的降级（Lowering）过程。
        
    - 理解如何为你的硬件实现一个简单的 Triton Backend，这涉及将 Triton 的 Block 语义映射到你芯片的 DMA 和向量指令上。
        

---

第二层：CuTe 与 CUTLASS —— 布局的代数 (The Algebra of Layouts)

时间：第 5-7 周

虽然你不用写 CUDA，但理解 NVIDIA 如何抽象高维张量布局，对于设计自研芯片的算子库至关重要。

- **2.1 CuTe：布局代数 (Layout Algebra)**
    
    - **核心概念**：CuTe 将布局定义为从逻辑坐标到物理索引的函数映射：$L: (c_0, c_1, \dots) \to i$。
        
    - **分层形状 (Hierarchical Shapes)**：理解类似 `((4, 8), 2)` 的形状描述。这比简单的 Row-major/Column-major 强大得多，能精确描述张量在寄存器或共享内存中的复杂排布。
        
    - **价值**：这一套代数理论是通用的。你可以借鉴这套思想来优化自研芯片上的数据排布，以减少 Bank Conflict。
        
- **2.2 GEMM 的五层抽象**
    
    - 学习 CUTLASS 3.x 如何将矩阵乘法解构为：Atom（指令级） -> Tiled MMA（微内核） -> Collective（通信与数据移动） -> Kernel（Grid 级） -> Device（API）。
        
    - **TMA (Tensor Memory Accelerator)**：了解 NVIDIA 如何在硬件层面支持异步数据拷贝，以及 CuTe 布局如何直接生成 TMA 描述符。
        

---

第三层：TileLang —— 显式调度与 NPU 适配 (Explicit Scheduling)

时间：第 8-10 周

TileLang (BitBLAS) 是 Triton 的有力补充，提供了更细粒度的控制，且对 NPU 支持更友好。

- **3.1 算法与调度解耦**
    
    - 学习 `T.Parallel`（线程绑定）、`T.Pipelined`（显式软件流水线）等原语。这允许你像写 CUDA 一样控制具体的并行策略，但保持了 Python 的语法。
        
- **3.2 跨架构适配**
    
    - TileLang 原生支持华为 Ascend NPU 和 AMD ROCm。研究它是如何针对不同硬件生成特定的指令流的，这对于你们公司的编译器团队极具参考价值。
        

---

#### 2. 精选学习资料推荐

**A. 必练实战项目 (High Priority)**

1. **Triton-Puzzles (GitHub)**
    
    - 这是学习 Triton 最有效的资源。它由 Sasha Rush 维护，提供了一系列难度递增的谜题。
        
    - _特点_：基于解释器运行，不需要 GPU 也能在 Colab 上调试逻辑。
        
    - _目标_：通关前 3 章（Vector Add, MatMul, Blocking）。
        
2. **PyTorch `torch.compile` 教程**
    
    - 官方教程：_Intermediate/torch_compile_tutorial.html_。
        
    - _重点_：开启 `TORCH_LOGS="graph_code"`，观察一个简单的 PyTorch 算子是如何被 Inductor 编译成 Triton 代码的。
        

**B. 深度理论阅读**

1. **OpenAI Triton 官方文档与论文**
    
    - 重点阅读关于 Block Pointer 和 Memory Coalescing 的章节。
        
2. **CUTLASS 3.x 设计文档**
    
    - 重点关注 CuTe 的 Layout 教程。虽然代码是 C++ 模板，但其核心思想是数学。
        
3. **TileLang (BitBLAS) 论文/代码**
    
    - 关注它是如何处理 NPU 后端的。
        

---

#### 3. 动手实践任务 (Actionable Tasks)

- **任务一：通关 Triton Puzzles**
    
    - **内容**：完成 GitHub 上的 `Triton-Puzzles`。
        
    - **深度**：在做矩阵乘法（MatMul）时，画出数据块在 HBM -> SRAM -> Registers 之间的移动路径。
        
- **任务二：分析 FlashAttention 的 Triton 实现**
    
    - **内容**：阅读 FlashAttention v2 的 Triton 源码（或其简化版教程）。
        
    - **思考**：它是如何通过重计算（Recomputation）来换取显存带宽的？如果不使用 Triton，在你的自研芯片上实现类似的逻辑需要哪些指令支持（如异步 DMA）？
        
- **任务三：编译器后端调研 (针对自研芯片)**
    
    - **内容**：在 PyTorch 中定义一个简单的自定义后端。
        
    - **代码**：    
		```python
		from torch._dynamo import register_backend
		@register_backend
		def my_backend(gm, example_inputs):
			print("Captured Graph:", gm.graph)
			return gm.forward
		```
        
    - **目的**：这是理解编译器栈的第一步。尝试思考如何将捕获到的 `gm.graph` 中的节点，替换为你公司自研芯片的算子库调用。
        

---

你对 Triton 的块级编程范式感兴趣吗？还是想先了解一下 CuTe 的布局代数？